{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7d1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from datasets import CardsDataset\n",
    "from augmentations import SSDAugmentation, BaseTransform\n",
    "from criterion import Criterion, Scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import detection_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import clear_output\n",
    "from torchvision.models.detection import ssd300_vgg16 as ssd300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d10904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seriy755\\project_SSD\\data\n"
     ]
    }
   ],
   "source": [
    "home = osp.expanduser(\"~\")\n",
    "\n",
    "get_dir = '\\project_SSD\\data'\n",
    "data_root = home+get_dir\n",
    "print(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2fd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = CardsDataset(root=data_root, mode='train', transform=SSDAugmentation())\n",
    "testdataset = CardsDataset(root=data_root, mode='test', transform=BaseTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122ad281",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(traindataset, batch_size=4, num_workers=0, shuffle=True, \n",
    "                        pin_memory=True, collate_fn=detection_collate)\n",
    "testloader = DataLoader(testdataset, batch_size=4, num_workers=0, shuffle=False, \n",
    "                        pin_memory=True, collate_fn=detection_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd61a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, opt_params, epochs, train_loader, val_loader, device, \n",
    "          scheduler=None, scheduler_params=None, resume=None):\n",
    "    writer = SummaryWriter()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    alpha = 1.5\n",
    "    \n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir=runs\n",
    "    \n",
    "    if resume is not None:\n",
    "        model.load_state_dict(torch.load(resume))\n",
    "        lr = opt_params['learning_rate'] \n",
    "    else:\n",
    "        lr = opt_params['learning_rate'] / 1e3\n",
    "    criterion = Criterion(opt, opt_params)\n",
    "    opt = criterion(model)\n",
    "    if scheduler is not None:\n",
    "        scheduler = Scheduler(scheduler, scheduler_params)\n",
    "        scheduler = scheduler(opt)\n",
    "    \n",
    "    n_iter_train = 0\n",
    "    n_iter_val = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        for imgs, labels in train_loader:\n",
    "            if device == 'cuda':\n",
    "                imgs = imgs.cuda(non_blocking=True)\n",
    "                for label in labels:\n",
    "                    label['boxes'] = label['boxes'].cuda(non_blocking=True)\n",
    "                    label['labels'] = label['labels'].cuda(non_blocking=True)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            losses = model(imgs, labels)\n",
    "            loss = alpha*losses['bbox_regression'] + losses['classification']\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if lr < opt_params['learning_rate']:\n",
    "                lr += (opt_params['learning_rate'] - opt_params['learning_rate'] / 1e3) / len(train_loader)\n",
    "                opt = criterion(model, lr)\n",
    "            \n",
    "            writer.add_scalar('LossIter/train', loss, n_iter_train+1)\n",
    "            n_iter_train += 1\n",
    "            \n",
    "            train_loss += loss / len(train_loader)\n",
    "                   \n",
    "        for imgs, labels in val_loader:\n",
    "            if device == 'cuda':\n",
    "                imgs = imgs.cuda(non_blocking=True)\n",
    "                for label in labels:\n",
    "                    label['boxes'] = label['boxes'].cuda(non_blocking=True)\n",
    "                    label['labels'] = label['labels'].cuda(non_blocking=True)\n",
    "            \n",
    "            losses = model(imgs, labels)\n",
    "            loss = alpha*losses['bbox_regression'].item() + losses['classification'].item()\n",
    "            \n",
    "            writer.add_scalar('LossIter/valid', loss, n_iter_val+1)\n",
    "            n_iter_val += 1\n",
    "            \n",
    "            val_loss += loss / len(val_loader)\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        writer.add_scalars('LossEpoch', {'Train': train_loss, 'Valid': val_loss}, epoch+1)\n",
    "        %load_ext tensorboard\n",
    "        %tensorboard --logdir=runs\n",
    "        \n",
    "        \n",
    "        print('On {} epoch train loss: {}; validation loss: {}'.format(epoch+1, train_loss, val_loss))\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            torch.save(model.state_dict(), 'weights/SSD300_epoch{}.pth'.format(epoch+1))\n",
    "            print('Weights on {} epoch is saved!'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84fae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES=7\n",
    "model = ssd300(num_classes=NUM_CLASSES, pretrained_backbone=True)\n",
    "optimizer = 'adam'\n",
    "opt_params = {'learning_rate': 1e-3, 'betas': (0.9, 0.999), 'weight_decay': 5e-4}\n",
    "scheduler = 'ReduceLROnPlateau'\n",
    "scheduler_params = {'mode': 'min', 'factor': 0.1, 'patience': 5, 'verbose': True,\n",
    "                   'threshold': 1e-4, 'threshold_mode': 'rel', 'cooldown': 0,\n",
    "                   'min_lr': 0, 'eps': 1e-8}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device='cuda'\n",
    "else:\n",
    "    device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93cc0b8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 29528), started 0:25:28 ago. (Use '!kill 29528' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8031560cd5091e4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8031560cd5091e4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 50 epoch train loss: 1.5327566862106323; validation loss: 4.987405507003561\n",
      "Weights on 50 epoch is saved!\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, opt_params, 50, trainloader, testloader, \n",
    "      device, scheduler, scheduler_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded3904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
